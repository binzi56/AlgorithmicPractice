# 海量数据问题

海量数据处理由于网上几篇文章已经总结的比较详细, 这里就不再铺开阐述;下面👇主要讲涉及的数据结构的特点以及背后的逻辑做相关说明;

### `Top K`问题
寻找热门查询，`300`万个查询字符串中统计最热门的`10`个查询?

分析：这些查询串的重复度比较高，虽然总数是`1千万`，但如果除去**重复**后，不超过`3百万`个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。

所以我们放弃**分而治之/hash映射**的步骤，直接上`hash_map`统计，然后排序。`So`，针对此类典型的`TOP K`问题，采取的对策往往是：`hash_map` + 堆。

解法：(有重复/数据量减少)
`hash_map`统计 + 堆排序

* [海量数据处理——分治和hash映射](https://blog.csdn.net/yangquanhui1991/article/details/52172768)

注:
如果要求速度, 可以采用空间换时间的策略;将数据分成`n`份(通过`hash`%`n`), 分别求出每一份的`Top K`再合并求总的`Top K`;

* [海量数据处理之Top K问题](https://blog.csdn.net/suibianshen2012/article/details/52003082)

附:
* [教你如何迅速秒杀99%的海量数据处理面试题](https://www.cnblogs.com/v-July-v/archive/2012/03/22/2413055.html)
* [十七道海量数据处理面试题与Bit-map详解](https://blog.csdn.net/v_JULY_v/article/details/6685962)
* [Hash表算法十道海量数据处理面试题](https://www.cnblogs.com/jackchen-Net/p/8111817.html)
* [大数据量及海量数据处理算法总结](https://blog.csdn.net/Master_Z/article/details/83968754)
* [海量数据问题简要总结](https://blog.csdn.net/SCUTJAY/article/details/105230282)
